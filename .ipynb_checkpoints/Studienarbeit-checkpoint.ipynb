{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Studienarbeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximilian Gaul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Laden Sie die Daten aus `adult.data` in einen Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdr = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education_num\",\n",
    "       \"marital_status\", \"occupation\", \"relationship\",\n",
    "      \"race\", \"sex\", \"capital_gain\", \"capital_loss\",\n",
    "      \"hours_per_week\", \"native_country\", \"income\"]\n",
    "df = pd.read_csv(\"adult.data\", skipinitialspace=True, names=hdr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>257302</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>154374</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>151910</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>201490</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>287927</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age         workclass  fnlwgt   education  education_num  \\\n",
       "0       39         State-gov   77516   Bachelors             13   \n",
       "1       50  Self-emp-not-inc   83311   Bachelors             13   \n",
       "2       38           Private  215646     HS-grad              9   \n",
       "3       53           Private  234721        11th              7   \n",
       "4       28           Private  338409   Bachelors             13   \n",
       "...    ...               ...     ...         ...            ...   \n",
       "32556   27           Private  257302  Assoc-acdm             12   \n",
       "32557   40           Private  154374     HS-grad              9   \n",
       "32558   58           Private  151910     HS-grad              9   \n",
       "32559   22           Private  201490     HS-grad              9   \n",
       "32560   52      Self-emp-inc  287927     HS-grad              9   \n",
       "\n",
       "           marital_status         occupation   relationship   race     sex  \\\n",
       "0           Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1      Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2                Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3      Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4      Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "...                   ...                ...            ...    ...     ...   \n",
       "32556  Married-civ-spouse       Tech-support           Wife  White  Female   \n",
       "32557  Married-civ-spouse  Machine-op-inspct        Husband  White    Male   \n",
       "32558             Widowed       Adm-clerical      Unmarried  White  Female   \n",
       "32559       Never-married       Adm-clerical      Own-child  White    Male   \n",
       "32560  Married-civ-spouse    Exec-managerial           Wife  White  Female   \n",
       "\n",
       "       capital_gain  capital_loss  hours_per_week native_country income  \n",
       "0              2174             0              40  United-States  <=50K  \n",
       "1                 0             0              13  United-States  <=50K  \n",
       "2                 0             0              40  United-States  <=50K  \n",
       "3                 0             0              40  United-States  <=50K  \n",
       "4                 0             0              40           Cuba  <=50K  \n",
       "...             ...           ...             ...            ...    ...  \n",
       "32556             0             0              38  United-States  <=50K  \n",
       "32557             0             0              40  United-States   >50K  \n",
       "32558             0             0              40  United-States  <=50K  \n",
       "32559             0             0              20  United-States  <=50K  \n",
       "32560         15024             0              40  United-States   >50K  \n",
       "\n",
       "[32561 rows x 15 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) In den nominalen Daten sind noch unbekannte Werte, gekennzeichnet durch `?`, vorhanden. Bereinigen Sie die Daten, indem Sie alle Zeilen entfernen, die unbekannte Werte enthalten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_builder(hdr, val):\n",
    "    query = ''\n",
    "    for h in hdr:\n",
    "        query += '{0} != \"{1}\" &'.format(str(h), str(val))\n",
    "    return query[:-1]\n",
    "\n",
    "df = df.query(query_builder(hdr, \"?\"), inplace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Entfernen Sie die Spalten `fnlwgt` und `income` als Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30162 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age         workclass   education  education_num      marital_status  \\\n",
       "0       39         State-gov   Bachelors             13       Never-married   \n",
       "1       50  Self-emp-not-inc   Bachelors             13  Married-civ-spouse   \n",
       "2       38           Private     HS-grad              9            Divorced   \n",
       "3       53           Private        11th              7  Married-civ-spouse   \n",
       "4       28           Private   Bachelors             13  Married-civ-spouse   \n",
       "...    ...               ...         ...            ...                 ...   \n",
       "32556   27           Private  Assoc-acdm             12  Married-civ-spouse   \n",
       "32557   40           Private     HS-grad              9  Married-civ-spouse   \n",
       "32558   58           Private     HS-grad              9             Widowed   \n",
       "32559   22           Private     HS-grad              9       Never-married   \n",
       "32560   52      Self-emp-inc     HS-grad              9  Married-civ-spouse   \n",
       "\n",
       "              occupation   relationship   race     sex  capital_gain  \\\n",
       "0           Adm-clerical  Not-in-family  White    Male          2174   \n",
       "1        Exec-managerial        Husband  White    Male             0   \n",
       "2      Handlers-cleaners  Not-in-family  White    Male             0   \n",
       "3      Handlers-cleaners        Husband  Black    Male             0   \n",
       "4         Prof-specialty           Wife  Black  Female             0   \n",
       "...                  ...            ...    ...     ...           ...   \n",
       "32556       Tech-support           Wife  White  Female             0   \n",
       "32557  Machine-op-inspct        Husband  White    Male             0   \n",
       "32558       Adm-clerical      Unmarried  White  Female             0   \n",
       "32559       Adm-clerical      Own-child  White    Male             0   \n",
       "32560    Exec-managerial           Wife  White  Female         15024   \n",
       "\n",
       "       capital_loss  hours_per_week native_country  \n",
       "0                 0              40  United-States  \n",
       "1                 0              13  United-States  \n",
       "2                 0              40  United-States  \n",
       "3                 0              40  United-States  \n",
       "4                 0              40           Cuba  \n",
       "...             ...             ...            ...  \n",
       "32556             0              38  United-States  \n",
       "32557             0              40  United-States  \n",
       "32558             0              40  United-States  \n",
       "32559             0              20  United-States  \n",
       "32560             0              40  United-States  \n",
       "\n",
       "[30162 rows x 13 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.copy()\n",
    "X = X.drop(columns=[\"fnlwgt\", \"income\"])\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Als Target soll das Feature `income` dienen, jedoch kommt nicht jeder Algorithmus mit nominalen Features klar. Konvertieren Sie das Target daher, sodass `income` den Wert `1` annimmt, falls das `income` ursprÃ¼nglich den Wert `>50K` hat und `0` andernfalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30157</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30158</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30159</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30160</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30161</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30162 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       income\n",
       "0           0\n",
       "1           0\n",
       "2           0\n",
       "3           0\n",
       "4           0\n",
       "...       ...\n",
       "30157       0\n",
       "30158       1\n",
       "30159       0\n",
       "30160       0\n",
       "30161       1\n",
       "\n",
       "[30162 rows x 1 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.DataFrame(\n",
    "    {\"income\": np.where(df['income'] == \">50K\", 1, 0)}\n",
    ")\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Wieviel Prozent der Personen haben ein Einkommen von mehr als `50.000$`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24892248524633645 % haben ein Einkommen von mehr als 50.000$\n"
     ]
    }
   ],
   "source": [
    "total = len(y.index)\n",
    "rich = len(y.query('income == 1').index)\n",
    "print(rich / total, \"% haben ein Einkommen von mehr als 50.000$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5) Was ist die Genauigkeit eines naiven Modells, welches unabhÃ¤ngig von den tatsÃ¤chlichen Features immer weniger als `50.000$` Einkommen zuweist? Dies ist das MindestmaÃŸ an Genauigkeit, an dem sich ihre spÃ¤teren Modelle messen mÃ¼ssen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 30162\n",
      "tn: 22654\n"
     ]
    }
   ],
   "source": [
    "tn = total - rich\n",
    "print(\"total:\", total)\n",
    "print(\"tn:\", tn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Genauigkeit ist definiert als $\\frac{tp + tn}{tp + tn + fp + fn}$\n",
    "\n",
    "`tp` ist die Anzahl der Personen, die das Modell als `>50k` einstuft und die auch tatsÃ¤chlich `>50k` verdienen. Im Fall des naiven Modells ist `tp = 0`.\n",
    "\n",
    "`tn` ist die Anzahl der Personen, die das Modell als `<=50k` einstuft und die auch tatsÃ¤chlich `<=50k` verdiene. Im Fall des naiven Modells ist `tn = 22654`.\n",
    "\n",
    "Der Wert des Nenners `tp + tn + fp + fn` entspricht der Gesamtzahl an DatensÃ¤tzen.\n",
    "Damit lÃ¤sst sich die Genauigkeit berechnen:\n",
    "\n",
    "$acc = \\frac{0 + 22654}{30162} = 0.7511\\%$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Schreiben Sie eine Methode `transform(X)` welche einen Feature-Dataframe `X` als Parameter erhÃ¤lt und einen transformierten DataFrame zurÃ¼ckgibt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die im Wertebereich verzerrten Features `capital_gain` und `capital_loss` sollten durch Logarithmierung normalisiert werden. Verwenden Sie dafÃ¼r die Funktion\n",
    "\n",
    "$$f: \\mathbb{R} \\rightarrow \\mathbb{R}, f(x) = log(x + 1)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: math.log(x + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(X):\n",
    "    _X = X.copy()\n",
    "    _X[\"capital_gain\"] = _X[\"capital_gain\"].apply(f)\n",
    "    _X[\"capital_loss\"] = _X[\"capital_loss\"].apply(f)\n",
    "    \n",
    "    numeric_headers = [\n",
    "        \"age\", \"education_num\", \"capital_gain\",\n",
    "        \"capital_loss\", \"hours_per_week\"\n",
    "    ]\n",
    "    \n",
    "    nominal_headers = [\n",
    "        \"workclass\", \"education\", \"marital_status\",\n",
    "        \"occupation\", \"relationship\",\n",
    "        \"race\", \"sex\", \"native_country\"\n",
    "    ]\n",
    "    \n",
    "    for nmh in numeric_headers:\n",
    "        min_max_scaler = preprocessing.MinMaxScaler()\n",
    "        _X[nmh] = min_max_scaler.fit_transform(_X[nmh].values.reshape(-1, 1))\n",
    "    _X = pd.get_dummies(_X)\n",
    "    #for nmh in nominal_headers:\n",
    "    #    dummies = pd.get_dummies(\n",
    "    #        data=_X, columns=[nmh]\n",
    "    #    )\n",
    "    #    _X[nmh] = dummies\n",
    "    \n",
    "    return _X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>education_num</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>workclass_Federal-gov</th>\n",
       "      <th>workclass_Local-gov</th>\n",
       "      <th>workclass_Private</th>\n",
       "      <th>workclass_Self-emp-inc</th>\n",
       "      <th>workclass_Self-emp-not-inc</th>\n",
       "      <th>...</th>\n",
       "      <th>native_country_Portugal</th>\n",
       "      <th>native_country_Puerto-Rico</th>\n",
       "      <th>native_country_Scotland</th>\n",
       "      <th>native_country_South</th>\n",
       "      <th>native_country_Taiwan</th>\n",
       "      <th>native_country_Thailand</th>\n",
       "      <th>native_country_Trinadad&amp;Tobago</th>\n",
       "      <th>native_country_United-States</th>\n",
       "      <th>native_country_Vietnam</th>\n",
       "      <th>native_country_Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.301370</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.667492</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.452055</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.287671</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.493151</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.150685</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>0.136986</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.377551</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>0.315068</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>0.561644</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>0.068493</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.193878</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>0.479452</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.835363</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30162 rows Ã— 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            age  education_num  capital_gain  capital_loss  hours_per_week  \\\n",
       "0      0.301370       0.800000      0.667492           0.0        0.397959   \n",
       "1      0.452055       0.800000      0.000000           0.0        0.122449   \n",
       "2      0.287671       0.533333      0.000000           0.0        0.397959   \n",
       "3      0.493151       0.400000      0.000000           0.0        0.397959   \n",
       "4      0.150685       0.800000      0.000000           0.0        0.397959   \n",
       "...         ...            ...           ...           ...             ...   \n",
       "32556  0.136986       0.733333      0.000000           0.0        0.377551   \n",
       "32557  0.315068       0.533333      0.000000           0.0        0.397959   \n",
       "32558  0.561644       0.533333      0.000000           0.0        0.397959   \n",
       "32559  0.068493       0.533333      0.000000           0.0        0.193878   \n",
       "32560  0.479452       0.533333      0.835363           0.0        0.397959   \n",
       "\n",
       "       workclass_Federal-gov  workclass_Local-gov  workclass_Private  \\\n",
       "0                          0                    0                  0   \n",
       "1                          0                    0                  0   \n",
       "2                          0                    0                  1   \n",
       "3                          0                    0                  1   \n",
       "4                          0                    0                  1   \n",
       "...                      ...                  ...                ...   \n",
       "32556                      0                    0                  1   \n",
       "32557                      0                    0                  1   \n",
       "32558                      0                    0                  1   \n",
       "32559                      0                    0                  1   \n",
       "32560                      0                    0                  0   \n",
       "\n",
       "       workclass_Self-emp-inc  workclass_Self-emp-not-inc  ...  \\\n",
       "0                           0                           0  ...   \n",
       "1                           0                           1  ...   \n",
       "2                           0                           0  ...   \n",
       "3                           0                           0  ...   \n",
       "4                           0                           0  ...   \n",
       "...                       ...                         ...  ...   \n",
       "32556                       0                           0  ...   \n",
       "32557                       0                           0  ...   \n",
       "32558                       0                           0  ...   \n",
       "32559                       0                           0  ...   \n",
       "32560                       1                           0  ...   \n",
       "\n",
       "       native_country_Portugal  native_country_Puerto-Rico  \\\n",
       "0                            0                           0   \n",
       "1                            0                           0   \n",
       "2                            0                           0   \n",
       "3                            0                           0   \n",
       "4                            0                           0   \n",
       "...                        ...                         ...   \n",
       "32556                        0                           0   \n",
       "32557                        0                           0   \n",
       "32558                        0                           0   \n",
       "32559                        0                           0   \n",
       "32560                        0                           0   \n",
       "\n",
       "       native_country_Scotland  native_country_South  native_country_Taiwan  \\\n",
       "0                            0                     0                      0   \n",
       "1                            0                     0                      0   \n",
       "2                            0                     0                      0   \n",
       "3                            0                     0                      0   \n",
       "4                            0                     0                      0   \n",
       "...                        ...                   ...                    ...   \n",
       "32556                        0                     0                      0   \n",
       "32557                        0                     0                      0   \n",
       "32558                        0                     0                      0   \n",
       "32559                        0                     0                      0   \n",
       "32560                        0                     0                      0   \n",
       "\n",
       "       native_country_Thailand  native_country_Trinadad&Tobago  \\\n",
       "0                            0                               0   \n",
       "1                            0                               0   \n",
       "2                            0                               0   \n",
       "3                            0                               0   \n",
       "4                            0                               0   \n",
       "...                        ...                             ...   \n",
       "32556                        0                               0   \n",
       "32557                        0                               0   \n",
       "32558                        0                               0   \n",
       "32559                        0                               0   \n",
       "32560                        0                               0   \n",
       "\n",
       "       native_country_United-States  native_country_Vietnam  \\\n",
       "0                                 1                       0   \n",
       "1                                 1                       0   \n",
       "2                                 1                       0   \n",
       "3                                 1                       0   \n",
       "4                                 0                       0   \n",
       "...                             ...                     ...   \n",
       "32556                             1                       0   \n",
       "32557                             1                       0   \n",
       "32558                             1                       0   \n",
       "32559                             1                       0   \n",
       "32560                             1                       0   \n",
       "\n",
       "       native_country_Yugoslavia  \n",
       "0                              0  \n",
       "1                              0  \n",
       "2                              0  \n",
       "3                              0  \n",
       "4                              0  \n",
       "...                          ...  \n",
       "32556                          0  \n",
       "32557                          0  \n",
       "32558                          0  \n",
       "32559                          0  \n",
       "32560                          0  \n",
       "\n",
       "[30162 rows x 103 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trans = transform(X)\n",
    "X_trans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitten Sie den Datensatz in einen Trainings- und Testdatensatz, wobei der Testdatensatz eine relative GrÃ¶ÃŸe von 20% haben soll. Verwenden Sie fÃ¼r die Reproduzierbarkeit einen `random_state = 0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_trans, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WÃ¤hlen Sie drei verschiedene, in der Vorlesung behandelte Modelltypen und trainieren Sie die entsprechenden Modelle mit den Standardparametern (keine Parameter). Geben Sie zu jedem Modell die Genauigkeit auf dem Testdatensatz aus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da es sich um ein (binÃ¤res) Klassifizierungsproblem handelt werden nur Modelltypen verwendet, die zur Klassifikation von Daten geeignet sind.\n",
    "\n",
    "Gleichzeitig ist nicht bekannt, ob die Daten linear separierbar sind, d.h. einfache Neuronale Netze wie Perzeptron oder Adaline sind ungeeignet.\n",
    "\n",
    "Daher werden folgende Modelle trainiert:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_to_accuracy(model, X_test, y_test):\n",
    "    model_predict = model.predict(X_test)\n",
    "    cf = confusion_matrix(\n",
    "        y_true=y_test, y_pred=model_predict, labels=[1, 0]\n",
    "    )\n",
    "\n",
    "    TP = cf[0][0]\n",
    "    FN = cf[0][1]\n",
    "    FP = cf[1][0]\n",
    "    TN = cf[1][1]\n",
    "\n",
    "    return (TP + TN) / (TP + TN + FP + FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genauigkeit LogisticRegression: 0.8392176363334991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:937: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression().fit(X_train, y_train.values.ravel())\n",
    "lr_accuracy = model_to_accuracy(lr, X_test, y_test)\n",
    "print(\"Genauigkeit LogisticRegression:\", lr_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Nearest-Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genauigkeit KNN: 0.8168407094314603\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier().fit(X_train, y_train.values.ravel())\n",
    "knn_accuracy = model_to_accuracy(knn, X_test, y_test)\n",
    "print(\"Genauigkeit KNN:\", knn_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Klassifikation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genauigkeit SVC: 0.8392176363334991\n"
     ]
    }
   ],
   "source": [
    "svc = SVC().fit(X_train, y_train.values.ravel())\n",
    "svc_accuracy = model_to_accuracy(svc, X_test, y_test)\n",
    "print(\"Genauigkeit SVC:\", svc_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WÃ¤hlen Sie das im vorherigen Schritt beste Modell und tunen Sie die Hyperparameter um mÃ¶glichst eine noch bessere Performance zu bekommen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Modell mit der besten Genauigkeit ist das `LogisticRegression`-Modell.\n",
    "\n",
    "Dieses Modell wird nun anhand der Hyperparameter `C`, `tol`, `solver` und `penalty` mit einer Rastersuche Ã¼ber alle Wertekombinationen getuned.\n",
    "\n",
    "Bestimme penalties kommen nur mit bestimmten solvern zurecht (und anders herum), darauf wird entsprechend RÃ¼cksicht genommen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying 360 combinations...\n",
      "We are at 10\n",
      "We are at 20\n",
      "We are at 30\n",
      "We are at 40\n",
      "We are at 50\n",
      "We are at 60\n",
      "We are at 70\n",
      "We are at 80\n",
      "We are at 90\n",
      "We are at 100\n",
      "We are at 110\n",
      "We are at 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:937: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:937: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at 130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:937: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:937: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at 140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:937: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:937: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at 160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:937: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:937: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at 170\n",
      "We are at 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:937: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:937: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at 190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:937: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:937: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at 210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:937: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:937: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at 220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:937: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:937: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at 230\n",
      "We are at 240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:937: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:937: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\svm\\_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at 250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:937: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:937: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at 260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at 270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:937: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:937: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at 280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:937: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:937: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at 290\n",
      "We are at 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:937: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:937: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\svm\\_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at 310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:937: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:937: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at 320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at 330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:937: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:937: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at 340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:937: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\test\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:937: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html.\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at 350\n",
      "We are at 360\n"
     ]
    }
   ],
   "source": [
    "C = [0.01, 0.05, 0.8, 2.0, 5.0, 10.0]\n",
    "tol = [1e-5, 1e-4, 1e-3, 1e-2]\n",
    "solver = [\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"]\n",
    "penalties = [\"l1\", \"l2\", \"elasticnet\"]\n",
    "\n",
    "combinations = len(C) * len(tol) * len(solver) * len(penalties)\n",
    "print(\"Trying\", combinations, \"combinations...\")\n",
    "\n",
    "i = np.arange(\n",
    "    0, combinations, 1\n",
    ")\n",
    "combination_dict = []\n",
    "\n",
    "vals = []\n",
    "for c in C:\n",
    "    for t in tol:\n",
    "        for s in solver:\n",
    "            for p in penalties:\n",
    "                l1_ratio = None\n",
    "                if p == \"elasticnet\":\n",
    "                    s = \"saga\"\n",
    "                    l1_ratio = 0.5\n",
    "                elif s in [\"newton-cg\", \"lbfgs\", \"sag\"]:\n",
    "                    p = \"l2\"\n",
    "                model = LogisticRegression(\n",
    "                    C=c, tol=t, penalty=p, solver=s, l1_ratio=l1_ratio\n",
    "                )\n",
    "                model.fit(X_train, y_train.values.ravel())\n",
    "                acc = model_to_accuracy(model, X_test, y_test)\n",
    "                vals.append(acc)\n",
    "                combination_dict.append({\n",
    "                    \"C\": c,\n",
    "                    \"tol\": t,\n",
    "                    \"solver\": s,\n",
    "                    \"penalty\": p,\n",
    "                    \"l1_ratio\": l1_ratio\n",
    "                })\n",
    "                if(len(vals) % 10 == 0):\n",
    "                    print(\"We are at\", len(vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(i, vals)\n",
    "plt.xlabel(\"Durchlauf i\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximale Genauigkeit 0.8415382065307475 fÃ¼r  {'C': 0.05, 'tol': 1e-05, 'solver': 'newton-cg', 'penalty': 'l2', 'l1_ratio': None}\n"
     ]
    }
   ],
   "source": [
    "best_comb = combination_dict[np.argmax(vals)]\n",
    "print(\"Maximale Genauigkeit\", np.array(vals).max(), \"fÃ¼r \", best_comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.05, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='newton-cg', tol=1e-05, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = LogisticRegression(\n",
    "    C=best_comb[\"C\"],\n",
    "    tol=best_comb[\"tol\"],\n",
    "    solver=best_comb[\"solver\"],\n",
    "    penalty=best_comb[\"penalty\"]\n",
    ")\n",
    "best_model.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Erstellen Sie einen DataFrame mit Werten fÃ¼r eine erfundene Person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>12</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     workclass  education  education_num marital_status    occupation  \\\n",
       "0   23  Self-emp-inc  Bachelors             12  Never-married  Tech-support   \n",
       "\n",
       "  relationship   race   sex  capital_gain  capital_loss  hours_per_week  \\\n",
       "0    Unmarried  White  Male             5             0              20   \n",
       "\n",
       "  native_country  \n",
       "0        Germany  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person = pd.DataFrame({\n",
    "    \"age\": 23,\n",
    "    \"workclass\": \"Self-emp-inc\",\n",
    "    \"education\": \"Bachelors\",\n",
    "    \"education_num\": 12,\n",
    "    \"marital_status\": \"Never-married\",\n",
    "    \"occupation\": \"Tech-support\",\n",
    "    \"relationship\": \"Unmarried\",\n",
    "    \"race\": \"White\",\n",
    "    \"sex\": \"Male\",\n",
    "    \"capital_gain\": 5,\n",
    "    \"capital_loss\": 0,\n",
    "    \"hours_per_week\": 20,\n",
    "    \"native_country\": \"Germany\"\n",
    "}, index=[0])\n",
    "person"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformieren Sie diese Person ebenfalls mit Hilfe der `transform`-Methode. Da die Normierung nur auf grÃ¶ÃŸeren DatensÃ¤tzen Sinn macht, vereinen Sie den ursprÃ¼nglichen DataFrame und die neue Person und transformieren das Gesamtpaket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xp = pd.concat((X, person))\n",
    "Xp_trans = transform(Xp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>education_num</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>workclass_Federal-gov</th>\n",
       "      <th>workclass_Local-gov</th>\n",
       "      <th>workclass_Private</th>\n",
       "      <th>workclass_Self-emp-inc</th>\n",
       "      <th>workclass_Self-emp-not-inc</th>\n",
       "      <th>...</th>\n",
       "      <th>native_country_Portugal</th>\n",
       "      <th>native_country_Puerto-Rico</th>\n",
       "      <th>native_country_Scotland</th>\n",
       "      <th>native_country_South</th>\n",
       "      <th>native_country_Taiwan</th>\n",
       "      <th>native_country_Thailand</th>\n",
       "      <th>native_country_Trinadad&amp;Tobago</th>\n",
       "      <th>native_country_United-States</th>\n",
       "      <th>native_country_Vietnam</th>\n",
       "      <th>native_country_Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.082192</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.15563</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.193878</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  education_num  capital_gain  capital_loss  hours_per_week  \\\n",
       "0  0.082192       0.733333       0.15563           0.0        0.193878   \n",
       "\n",
       "   workclass_Federal-gov  workclass_Local-gov  workclass_Private  \\\n",
       "0                      0                    0                  0   \n",
       "\n",
       "   workclass_Self-emp-inc  workclass_Self-emp-not-inc  ...  \\\n",
       "0                       1                           0  ...   \n",
       "\n",
       "   native_country_Portugal  native_country_Puerto-Rico  \\\n",
       "0                        0                           0   \n",
       "\n",
       "   native_country_Scotland  native_country_South  native_country_Taiwan  \\\n",
       "0                        0                     0                      0   \n",
       "\n",
       "   native_country_Thailand  native_country_Trinadad&Tobago  \\\n",
       "0                        0                               0   \n",
       "\n",
       "   native_country_United-States  native_country_Vietnam  \\\n",
       "0                             0                       0   \n",
       "\n",
       "   native_country_Yugoslavia  \n",
       "0                          0  \n",
       "\n",
       "[1 rows x 103 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tail = Xp_trans.tail(1)\n",
    "tail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Machen Sie mit Hilfe des Modells eine Vorhersage. WÃ¼rde die Person als potentieller Spender ausgewÃ¤hlt werden?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = best_model.predict(Xp_trans)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Person wÃ¼rde nicht als potentieller Spender ausgewÃ¤hlt werden da die Vorhersage die Klasse `0` zurÃ¼ckliefert (`<=50k`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
