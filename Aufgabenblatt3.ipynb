{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Laden Sie die CSV `Weekly.csv` in einen Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.read_csv(\"Weekly.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Verschaffen Sie sich einen Überblick über die Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Lag1</th>\n",
       "      <th>Lag2</th>\n",
       "      <th>Lag3</th>\n",
       "      <th>Lag4</th>\n",
       "      <th>Lag5</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Today</th>\n",
       "      <th>Direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1990</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.572</td>\n",
       "      <td>-3.936</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>-3.484</td>\n",
       "      <td>0.154976</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>Down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1990</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.572</td>\n",
       "      <td>-3.936</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>0.148574</td>\n",
       "      <td>-2.576</td>\n",
       "      <td>Down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1990</td>\n",
       "      <td>-2.576</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.572</td>\n",
       "      <td>-3.936</td>\n",
       "      <td>0.159837</td>\n",
       "      <td>3.514</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1990</td>\n",
       "      <td>3.514</td>\n",
       "      <td>-2.576</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.572</td>\n",
       "      <td>0.161630</td>\n",
       "      <td>0.712</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1990</td>\n",
       "      <td>0.712</td>\n",
       "      <td>3.514</td>\n",
       "      <td>-2.576</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.153728</td>\n",
       "      <td>1.178</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1084</td>\n",
       "      <td>2010</td>\n",
       "      <td>-0.861</td>\n",
       "      <td>0.043</td>\n",
       "      <td>-2.173</td>\n",
       "      <td>3.599</td>\n",
       "      <td>0.015</td>\n",
       "      <td>3.205160</td>\n",
       "      <td>2.969</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1085</td>\n",
       "      <td>2010</td>\n",
       "      <td>2.969</td>\n",
       "      <td>-0.861</td>\n",
       "      <td>0.043</td>\n",
       "      <td>-2.173</td>\n",
       "      <td>3.599</td>\n",
       "      <td>4.242568</td>\n",
       "      <td>1.281</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1086</td>\n",
       "      <td>2010</td>\n",
       "      <td>1.281</td>\n",
       "      <td>2.969</td>\n",
       "      <td>-0.861</td>\n",
       "      <td>0.043</td>\n",
       "      <td>-2.173</td>\n",
       "      <td>4.835082</td>\n",
       "      <td>0.283</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1087</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.283</td>\n",
       "      <td>1.281</td>\n",
       "      <td>2.969</td>\n",
       "      <td>-0.861</td>\n",
       "      <td>0.043</td>\n",
       "      <td>4.454044</td>\n",
       "      <td>1.034</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1088</td>\n",
       "      <td>2010</td>\n",
       "      <td>1.034</td>\n",
       "      <td>0.283</td>\n",
       "      <td>1.281</td>\n",
       "      <td>2.969</td>\n",
       "      <td>-0.861</td>\n",
       "      <td>2.707105</td>\n",
       "      <td>0.069</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1089 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Year   Lag1   Lag2   Lag3   Lag4   Lag5    Volume  Today Direction\n",
       "0     1990  0.816  1.572 -3.936 -0.229 -3.484  0.154976 -0.270      Down\n",
       "1     1990 -0.270  0.816  1.572 -3.936 -0.229  0.148574 -2.576      Down\n",
       "2     1990 -2.576 -0.270  0.816  1.572 -3.936  0.159837  3.514        Up\n",
       "3     1990  3.514 -2.576 -0.270  0.816  1.572  0.161630  0.712        Up\n",
       "4     1990  0.712  3.514 -2.576 -0.270  0.816  0.153728  1.178        Up\n",
       "...    ...    ...    ...    ...    ...    ...       ...    ...       ...\n",
       "1084  2010 -0.861  0.043 -2.173  3.599  0.015  3.205160  2.969        Up\n",
       "1085  2010  2.969 -0.861  0.043 -2.173  3.599  4.242568  1.281        Up\n",
       "1086  2010  1.281  2.969 -0.861  0.043 -2.173  4.835082  0.283        Up\n",
       "1087  2010  0.283  1.281  2.969 -0.861  0.043  4.454044  1.034        Up\n",
       "1088  2010  1.034  0.283  1.281  2.969 -0.861  2.707105  0.069        Up\n",
       "\n",
       "[1089 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Erstellen Sie mit `sklearn.linear_model.LogisticRegression` einen Klassifikator von `Lag1` bis `Lag5` und `Volume` auf `Direction`. Teilen Sie dabei den Datensatz in zwei in etwa gleich große Trainings- und Testdatensätze bei `random_state=0` auf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Lag1</th>\n",
       "      <th>Lag2</th>\n",
       "      <th>Lag3</th>\n",
       "      <th>Lag4</th>\n",
       "      <th>Lag5</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Today</th>\n",
       "      <th>Direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1990</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.572</td>\n",
       "      <td>-3.936</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>-3.484</td>\n",
       "      <td>0.154976</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1990</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.572</td>\n",
       "      <td>-3.936</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>0.148574</td>\n",
       "      <td>-2.576</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1990</td>\n",
       "      <td>-2.576</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.572</td>\n",
       "      <td>-3.936</td>\n",
       "      <td>0.159837</td>\n",
       "      <td>3.514</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1990</td>\n",
       "      <td>3.514</td>\n",
       "      <td>-2.576</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.572</td>\n",
       "      <td>0.161630</td>\n",
       "      <td>0.712</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1990</td>\n",
       "      <td>0.712</td>\n",
       "      <td>3.514</td>\n",
       "      <td>-2.576</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.153728</td>\n",
       "      <td>1.178</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1084</td>\n",
       "      <td>2010</td>\n",
       "      <td>-0.861</td>\n",
       "      <td>0.043</td>\n",
       "      <td>-2.173</td>\n",
       "      <td>3.599</td>\n",
       "      <td>0.015</td>\n",
       "      <td>3.205160</td>\n",
       "      <td>2.969</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1085</td>\n",
       "      <td>2010</td>\n",
       "      <td>2.969</td>\n",
       "      <td>-0.861</td>\n",
       "      <td>0.043</td>\n",
       "      <td>-2.173</td>\n",
       "      <td>3.599</td>\n",
       "      <td>4.242568</td>\n",
       "      <td>1.281</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1086</td>\n",
       "      <td>2010</td>\n",
       "      <td>1.281</td>\n",
       "      <td>2.969</td>\n",
       "      <td>-0.861</td>\n",
       "      <td>0.043</td>\n",
       "      <td>-2.173</td>\n",
       "      <td>4.835082</td>\n",
       "      <td>0.283</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1087</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.283</td>\n",
       "      <td>1.281</td>\n",
       "      <td>2.969</td>\n",
       "      <td>-0.861</td>\n",
       "      <td>0.043</td>\n",
       "      <td>4.454044</td>\n",
       "      <td>1.034</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1088</td>\n",
       "      <td>2010</td>\n",
       "      <td>1.034</td>\n",
       "      <td>0.283</td>\n",
       "      <td>1.281</td>\n",
       "      <td>2.969</td>\n",
       "      <td>-0.861</td>\n",
       "      <td>2.707105</td>\n",
       "      <td>0.069</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1089 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Year   Lag1   Lag2   Lag3   Lag4   Lag5    Volume  Today  Direction\n",
       "0     1990  0.816  1.572 -3.936 -0.229 -3.484  0.154976 -0.270          0\n",
       "1     1990 -0.270  0.816  1.572 -3.936 -0.229  0.148574 -2.576          0\n",
       "2     1990 -2.576 -0.270  0.816  1.572 -3.936  0.159837  3.514          1\n",
       "3     1990  3.514 -2.576 -0.270  0.816  1.572  0.161630  0.712          1\n",
       "4     1990  0.712  3.514 -2.576 -0.270  0.816  0.153728  1.178          1\n",
       "...    ...    ...    ...    ...    ...    ...       ...    ...        ...\n",
       "1084  2010 -0.861  0.043 -2.173  3.599  0.015  3.205160  2.969          1\n",
       "1085  2010  2.969 -0.861  0.043 -2.173  3.599  4.242568  1.281          1\n",
       "1086  2010  1.281  2.969 -0.861  0.043 -2.173  4.835082  0.283          1\n",
       "1087  2010  0.283  1.281  2.969 -0.861  0.043  4.454044  1.034          1\n",
       "1088  2010  1.034  0.283  1.281  2.969 -0.861  2.707105  0.069          1\n",
       "\n",
       "[1089 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Direction\"] = df[\"Direction\"].map({\"Up\": 1, \"Down\": 0})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "Xtrain, Xtest = train_test_split(df[[\"Lag1\", \"Lag2\", \"Lag3\", \"Lag4\", \"Lag5\", \"Volume\"]], test_size=0.5, random_state=0)\n",
    "ytrain, ytest = train_test_split(df[\"Direction\"], test_size=0.5, random_state=0)\n",
    "\n",
    "lr = LogisticRegression().fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Erstellen Sie mit `sklearn.metrics.confusion_matrix` die Wahrheitsmatrix der Vorhersage auf den Testdaten. Legen Sie dabei die Reihenfolge der Labels auf `Up` gefolgt von `Down` fest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[228,  83],\n",
       "       [171,  63]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred = lr.predict(Xtest)\n",
    "cf = confusion_matrix(y_true=ytest, y_pred=ypred, labels=[1, 0])\n",
    "cf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Berechnen Sie manuell die Größen `Genauigkeit`, `Präzision` und `Trefferquote`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genauigkeit ($\\frac{TP + TN}{TP + TN + FP + FN}$): Anteil der korrekt klassifizierten Daten am Gesamtdatensatz\n",
    "\n",
    "Präzision ($\\frac{TP}{TP + FP}$): Anteil der korrekt positiv vorhergesagten Datensätze an der Gesamtheit der als positiv vorhergesagten Datensätze\n",
    "\n",
    "Trefferquote ($\\frac{TP}{FP + FN}$): Anteil der korrekt positiv vorhergesagten Datensätze an der Gesamtheit der echt positiven Datensätze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genaugikeit: 0.5339449541284403 \n",
      "Präzision: 0.5714285714285714 \n",
      "Trefferquote: 0.8976377952755905\n"
     ]
    }
   ],
   "source": [
    "TP = cf[0][0]\n",
    "FN = cf[0][1]\n",
    "FP = cf[1][0]\n",
    "TN = cf[1][1]\n",
    "\n",
    "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "precision = TP / (TP + FP)\n",
    "recall = TP / (FP + FN)\n",
    "print(\"Genaugikeit:\", accuracy, \"\\nPräzision:\", precision, \"\\nTrefferquote:\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Interpretieren Sie das Ergebnis. Wenn Sie auf Kursgewinne setzen wollen, könnten Sie sich auf das Modell verlassen? Welche Metrik ziehen Sie für diese Aussage heran?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der wichtige Wert hierfür ist die Trefferquote (`recall`) da sie den Anteil an korrekt positiv vorhergesagten Datensätze (`UP`) an der Gesamtheit der echt positiven Datensätze angibt. Ein Wert von ~0.90 ist sehr gut."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) Trainieren Sie ein neues logistisches Regressionsmodell, diesmal lediglich von `Lag2` auf `Direction`. Verwenden Sie ebenfalls eine gleichmäßige Aufteilung des Datensatzes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "Xtrain, Xtest = train_test_split(df[[\"Lag2\"]], test_size=0.5, random_state=0)\n",
    "ytrain, ytest = train_test_split(df[\"Direction\"], test_size=0.5, random_state=0)\n",
    "\n",
    "lr = LogisticRegression().fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8) Erstellen Sie mit `matplotlib.pyplot` einen Plot der Klassenwahrscheinlichkeiten von `Down` und `Up` in Abhängigkeit von `Lag2` anhand des Modells für $lag2\\in [-50,50]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lag2_vals = np.arange(-50, 50, 0.5)\n",
    "probabilities = lr.predict_proba(X=lag2_vals.reshape(-1,1))\n",
    "down = plt.scatter(x=lag2_vals, y=probabilities[:, 0], s=2)\n",
    "up = plt.scatter(x=lag2_vals, y=probabilities[:, 1], s=2)\n",
    "plt.xlabel(\"Lag2\")\n",
    "plt.ylabel(\"Probabilitty\")\n",
    "plt.legend((up, down), ('UP', 'DOWN'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9) Wo befindet sich die Entscheidungsoberfläche? Wie lautet die Klassifikationsregel des Modells?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ab einer prozentualen Rendite zu 2 Wochen zuvor von $> 0\\%$ wird als `UP` klassifiziert, ansonsten als `DOWN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
